# NLU-with-BERT
:writing_hand: This repo indicates the example implementation of SemBERT for NLU tasks. I employed the pre-trained BERT uncased models in order not to forget to pass the parameter. <br/>
	:zap: The POS tags are narrowly different using various spaCy versions. SemBERT utilized spacy==2.0.18 to obtain the verbs. <br/>
:zap: The experiment environment for reference: Python 3.6+ PyTorch (1.0.0) AllenNLP (0.8.1) <br/>
:loudspeaker: If you deploy the original data instead of the preprocessed one by tag_model/tagger_offline.py, please modify the index according to the dataset structure. <br/>
:zap: I will try to add step by step instructions.....
